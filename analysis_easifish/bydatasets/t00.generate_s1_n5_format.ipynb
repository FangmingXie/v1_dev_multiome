{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a9b59-b2c0-4c6b-9955-3cd6c1e7bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ebb51-32ac-418e-a698-64372533e29b",
   "metadata": {},
   "source": [
    "https://docs.python.org/3/library/xml.etree.elementtree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352f35e-6c1f-4941-8004-b77d90efeaf8",
   "metadata": {},
   "source": [
    "# working version - v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025ca82-b6d5-4792-8760-b76da29155de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xml_s1(f_src, f_dst):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tree = ET.parse(f_src)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    ## show\n",
    "    # get viewSetups - voxelSize and image size\n",
    "    for viewsetup in root[1][1].findall('ViewSetup'):\n",
    "        print(viewsetup.find('voxelSize').find('size').text)\n",
    "        print(viewsetup.find('size').text)\n",
    "    \n",
    "    # get viewRegistrations - ViewTransform\n",
    "    for viewreg in root.find('ViewRegistrations').findall('ViewRegistration'):\n",
    "        for viewtrans in viewreg.findall('ViewTransform'):\n",
    "            # print(viewtrans.find('Name').text)\n",
    "            print(viewtrans.find('affine').text)\n",
    "            \n",
    "    print('---')\n",
    "    \n",
    "    ## modify\n",
    "    for viewsetup in root[1][1].findall('ViewSetup'):\n",
    "        a = viewsetup.find('voxelSize').find('size').text\n",
    "        b = viewsetup.find('size').text\n",
    "    \n",
    "        a = np.array(a.split(' ')).astype(float)\n",
    "        a[:2] = a[:2]*2\n",
    "        a = \" \".join(a.astype(str).tolist())\n",
    "        \n",
    "        b = np.array(b.split(' ')).astype(int)\n",
    "        b[:2] = b[:2]/2\n",
    "        b = \" \".join(b.astype(str).tolist())\n",
    "    \n",
    "        print(a)    \n",
    "        print(b)    \n",
    "        viewsetup.find('voxelSize').find('size').text = a\n",
    "        viewsetup.find('size').text = b\n",
    "        \n",
    "    for viewreg in root.find('ViewRegistrations').findall('ViewRegistration'):\n",
    "        for viewtrans in viewreg.findall('ViewTransform'):\n",
    "            transform_type = viewtrans.find('Name').text\n",
    "            transform_vals = viewtrans.find('affine').text\n",
    "            a = transform_vals\n",
    "            a = np.array(a.split(' ')).astype(float)\n",
    "            \n",
    "            if transform_type == 'Translation':\n",
    "                a[3] = a[3]/2\n",
    "                a[7] = a[7]/2\n",
    "                \n",
    "            elif transform_type == 'calibration':\n",
    "                a[10] = a[10]/2\n",
    "            else:\n",
    "                raise ValueError('transform_type should be Translation or calibration only')\n",
    "                \n",
    "            a = \" \".join(a.astype(str).tolist())\n",
    "            print(a)    \n",
    "            viewtrans.find('affine').text = a\n",
    "            \n",
    "    tree.write(f_dst, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6174e5-0d2e-499a-aa51-cff69c52d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_setup_attributes_s0_s1(f_n5):\n",
    "    \"\"\"\n",
    "    # update attributes\n",
    "    # 1. if attributes_s0 doesn't exist - copy from attributes\n",
    "    # 2. use attrbutes_s0 to generate attributes_s1\n",
    "    # 3. copy attributes_s1 as attributes\n",
    "    \"\"\"\n",
    "    \n",
    "    for view_setup in sorted(glob.glob(os.path.join(f_n5, 'setup*'))):\n",
    "        f_attr    = os.path.join(view_setup, 'attributes.json')\n",
    "        f_attr_s0 = os.path.join(view_setup, 'attributes_s0.json')\n",
    "        f_attr_s1 = os.path.join(view_setup, 'attributes_s1.json')\n",
    "        \n",
    "        if not os.path.isfile(f_attr):\n",
    "            raise ValueError(\"attributes.json doesn't exist\")\n",
    "            \n",
    "        if not os.path.isfile(f_attr_s0):\n",
    "            print('copy attributes.json as attributes_s0.json')\n",
    "            shutil.copyfile(f_attr, f_attr_s0)\n",
    "            \n",
    "        if not os.path.isfile(f_attr_s1):\n",
    "            print('generate attributes_s1.json from attributes_s0.json')\n",
    "            with open(f_attr_s0, 'r') as fi:\n",
    "                data = json.load(fi)\n",
    "            \n",
    "                a = data['downsamplingFactors']\n",
    "                print('befor:', a)\n",
    "                a = np.array(a).astype(int)\n",
    "                a[:,:2] = (a[:,:2]/2).astype(int)\n",
    "                a = a.tolist()\n",
    "                print('after:', a)\n",
    "                data['downsamplingFactors'] = a\n",
    "                \n",
    "            with open(f_attr_s1, 'w') as fo:\n",
    "                json.dump(data, fo)\n",
    "    return\n",
    "\n",
    "def set_attributes(f_n5, level):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for view_setup in sorted(glob.glob(os.path.join(f_n5, 'setup*'))):\n",
    "        f_attr    = os.path.join(view_setup, 'attributes.json')\n",
    "        f_attr_s0 = os.path.join(view_setup, 'attributes_s0.json')\n",
    "        f_attr_s1 = os.path.join(view_setup, 'attributes_s1.json')\n",
    "\n",
    "        if level == 's0':\n",
    "            f_src = f_attr_s0\n",
    "        elif level == 's1':\n",
    "            f_src = f_attr_s1\n",
    "        else:\n",
    "            raise ValueError('level must be s0 or s1')\n",
    "            \n",
    "        if os.path.isfile(f_attr_s0) and os.path.isfile(f_attr_s1):\n",
    "            if os.path.isfile(f_attr):\n",
    "                os.remove(f_attr)\n",
    "            shutil.copyfile(f_src, f_attr)\n",
    "        else:\n",
    "            raise ValueError('attributes_s0.json and attributes_s1.json must both exist')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b9ced-e9db-498b-b934-5bec6320a062",
   "metadata": {},
   "source": [
    "# test everything\n",
    "- verify in BigStitcher by toggle between `s1` and `s0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40763e07-5525-425a-ac50-d447843b959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_n5 = '/u/home/f/f7xiesnm/project-zipursky/data/00_tiled/sparse06_r1.n5/'\n",
    "f_xml_old = '/u/home/f/f7xiesnm/project-zipursky/data/00_tiled/lt185_r2.xml'\n",
    "f_xml_new = '/u/home/f/f7xiesnm/project-zipursky/data/00_tiled/lt185_r2_autos1.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0f9fe-56d6-4967-ab1e-c68abac97873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_xml_s1(f_xml_old, f_xml_new)\n",
    "\n",
    "# no need to change attributes\n",
    "# generate_setup_attributes_s0_s1(f_n5)\n",
    "# set_attributes(f_n5, 's1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7442a-cea4-4da5-a7d3-228258eaa856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
