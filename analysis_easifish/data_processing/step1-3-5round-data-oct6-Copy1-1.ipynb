{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3becb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('..')\n",
    "from os.path import abspath, dirname\n",
    "import zarr\n",
    "import z5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "from skimage.measure import regionprops\n",
    "from skimage.io import imread, imsave\n",
    "from scipy import stats\n",
    "from scipy.stats import skewnorm, lognorm\n",
    "from scipy.optimize import minimize\n",
    "import itertools\n",
    "\n",
    "from easi_fish import n5_metadata_utils as n5mu\n",
    "from easi_fish import roi_prop, spot, intensity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import importlib\n",
    "importlib.reload(spot)\n",
    "importlib.reload(roi_prop)\n",
    "importlib.reload(intensity)\n",
    "\n",
    "\"\"\"\n",
    "Spot counts for cells with highly expressed genes (dense spots)\n",
    "1. Measure total intensity of every ROI after bleed-through correction and background subtraction.\n",
    "2. Calculate the number of spot from total intensity based on unit-spot intensity\n",
    "3. Correlate the number of spots (from air-localize) with the total fluorescence intensity/voxel in each ROI and determine a 'cutoff'. \n",
    "   Spot count > cutoff: use spot count converted based on total fluorescence intensity; \n",
    "   Spot count < cutoff: use spot count from Airlocalize\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unit_spot_intn(path_spot):\n",
    "    \"\"\"estimate unit spot intensity\n",
    "    \"\"\"\n",
    "    spot = np.loadtxt(path_spot, delimiter=',')\n",
    "    # (x, y, z, I)\n",
    "    vox=[0.92,0.92,0.84]\n",
    "    spot[:,:3]=spot[:,:3]/vox  # convert from physical unit to pixel unit\n",
    "    ##remove spots on edges (eliminate false detection)\n",
    "    spot = spot[np.logical_and(spot[:,0]<=1500, spot[:,0]>250)]\n",
    "    spot = spot[np.logical_and(spot[:,1]<=1500, spot[:,1]>250)]\n",
    "    spot = spot[np.logical_and(spot[:,2]<=650,  spot[:,2]>150)]   \n",
    "    \n",
    "    ## assign the most frequent intensity as the single-spot-intensity\n",
    "    spot_int = spot[:,3]\n",
    "    spot_int = spot_int[spot_int!=-8.0] # ???\n",
    "    n,b=np.histogram(spot_int, bins=5000)\n",
    "    unit_intn = b[np.argmax(n)]\n",
    "    \n",
    "    return unit_intn\n",
    "\n",
    "def get_spot_counts_from_intn(path_intn, path_spot, roi_meta):\n",
    "    \"\"\"estimate spot_counts from cell_intensities; estimate unit-spot intensity first\n",
    "    \"\"\"\n",
    "    unit_intn = get_unit_spot_intn(path_spot) # get unit intn\n",
    "    \n",
    "    cell_int = pd.read_csv(path_intn, sep=',', index_col=0)\n",
    "    cell_int = cell_int.reindex(roi_meta.index) ## only include intact ROIs###\n",
    "\n",
    "    vec_mean = cell_int['mean_intensity'].values\n",
    "    vec_area = roi_meta['area'].values\n",
    "\n",
    "    # background\n",
    "    n,b = np.histogram(vec_mean, bins=1000)\n",
    "    bg = b[np.argmax(n)]    \n",
    "    \n",
    "    # count\n",
    "    vec_count = np.clip(vec_mean - bg, 0, None)*vec_area/unit_intn\n",
    "    return vec_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d89d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input\n",
    "# input_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\"\n",
    "input_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt172_exps\\\\gene\\\\outputs\"\n",
    "bleed_thru_epsilon = 1\n",
    "output_dir = os.path.join(input_dir, f\"test-oct6_epsilon{bleed_thru_epsilon}\")  \n",
    "\n",
    "# fixed image (directory - n5 format)\n",
    "# fix_dir = os.path.join(input_dir, \"r2\\\\export_sigma3.n5\")\n",
    "fix_dir = os.path.join(input_dir, \"lt172_gene_r3\\\\export.n5\")\n",
    "# get appropriate image data within fix_dir\n",
    "subpath='\\\\c3\\\\s2' # what does the subpath mean?\n",
    "\n",
    "# segmentation mask (tif format accepted here)\n",
    "lb_dir  = os.path.join(input_dir, \"lt172_gene_r3\\\\segmentation\\\\lt172_gene_r3-c3.tif\" ) \n",
    "\n",
    "# registered image (directory - n5 format)\n",
    "# reg_dir = os.path.join(input_dir, \"lt172_gene_r1\\\\registration\\\\lt171_gene_4tile_r1-to-lt171_gene_4tile_r2\\\\warped\")  \n",
    "reg_dirs = [\n",
    "    os.path.join(input_dir, \"lt172_gene_r1\\\\registration\\lt172_gene_r1-to-lt172_gene_r3\\\\warped\"),\n",
    "    os.path.join(input_dir, \"lt172_gene_r4\\\\registration\\lt172_gene_r4-to-lt172_gene_r3\\\\warped\"),\n",
    "    os.path.join(input_dir, \"lt172_gene_r5\\\\registration\\lt172_gene_r5-to-lt172_gene_r3\\\\warped\"),\n",
    "]\n",
    "\n",
    "# spot dir \n",
    "spot_dir = os.path.join(input_dir, \"spots_pooled\") # pool spots together; warpped and fixed\n",
    "intn_dir = os.path.join(input_dir, \"intensities_pooled\") # pool spots together; warpped and fixed\n",
    "# for every gene\n",
    "rounds = ['r1', 'r3', 'r4', 'r5']\n",
    "channels = ['c0', 'c1', 'c2', 'c4']\n",
    "# r1 should be the wrappped one\n",
    "fx_spots = [os.path.join(spot_dir, f'spots_{r}_{c}.txt') \n",
    "                 for r, c in itertools.product(rounds, channels)]\n",
    "fx_intns = [os.path.join(intn_dir, f'{r}_{c}_intensity.csv') \n",
    "                 for r, c in itertools.product(rounds, channels)]\n",
    "\n",
    "for f in fx_spots:\n",
    "    assert os.path.isfile(f)\n",
    "for f in fx_intns:\n",
    "    assert os.path.isfile(f)\n",
    "\n",
    "## output\n",
    "# out_mask = os.path.join(output_dir, 'mask.tif')\n",
    "out_badroi = os.path.join(output_dir, 'bad_roi_list.npy')\n",
    "out_allroi = os.path.join(output_dir, \"roi_all.csv\") \n",
    "out_roi = os.path.join(output_dir, \"roi.csv\") \n",
    "out_spots = os.path.join(output_dir, \"spotcount.csv\")\n",
    "out_spots_intn = os.path.join(output_dir, \"spotcount_intn.csv\")\n",
    "# out_intensity = os.path.join(output_dir, \"intensity_c0_r2.csv\")\n",
    "out_spots_merged = os.path.join(output_dir, 'spotcount_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# output dir\n",
    "if not os.path.isdir(output_dir):\n",
    "    print(output_dir)\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "#voxel size in Âµm (x, y, z) (post-expansion)\n",
    "vox= n5mu.read_voxel_spacing(fix_dir, subpath)\n",
    "#image size in pixel (x, y, z)\n",
    "grid=n5mu.read_voxel_grid(fix_dir, subpath)\n",
    "#image size in physical space (x, y, z) (post-expansion)\n",
    "size=grid*vox\n",
    "print('voxel size is:',vox)\n",
    "print('image size in pixel unit is:',grid)\n",
    "print('image size in um unit is:',size)\n",
    "\n",
    "# get appropriate image data\n",
    "print(\"loading images...\")\n",
    "# fix = zarr.open(store=zarr.N5Store(fix_dir), mode='r')     \n",
    "# img1 = fix[subpath][:, :, :]\n",
    "\n",
    "lb=imread(lb_dir)\n",
    "print(lb.shape)\n",
    "roi = np.max(lb)\n",
    "print(roi)\n",
    "\n",
    "mask=np.full((grid[2], grid[1], grid[0]),1)\n",
    "for reg_dir in reg_dirs:\n",
    "    reg = zarr.open(store=zarr.N5Store(reg_dir), mode='r')     \n",
    "    img2 = reg[subpath][:, :, :]\n",
    "    print(\"image loaded\")\n",
    "    mask[img2==0]=0\n",
    "    \n",
    "# imsave(out_mask, mask)\n",
    "print(\"mask generated\")\n",
    "print(\"mask dimension is:\", mask.shape)\n",
    "\n",
    "# # Get list of ROIs that are fully or partially outside the mask \n",
    "### Make sure to only include ROIs that are intact and in the overlapping regions across all rounds of FISH\n",
    "bad_roi=np.unique(lb[mask==0])\n",
    "if bad_roi[0] == 0:\n",
    "    bad_roi = bad_roi[1:]\n",
    "np.save(out_badroi, bad_roi)\n",
    "print(\"# of ROIs rejected:\", len(bad_roi))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "roi_meta_all = roi_prop.roi_prop_v2(lb)\n",
    "roi_meta_all.to_csv(out_allroi)\n",
    "\n",
    "roi_meta = roi_meta_all.set_index('roi').copy()\n",
    "roi_meta = roi_meta.loc[roi_meta.index.difference(bad_roi)]\n",
    "roi_meta.to_csv(out_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c53b42-c8ad-4379-a404-dc87fc9f933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bleed through!\n",
    "spots_bld_thru_removed = {}\n",
    "c_qry = 'c0'\n",
    "c_ref = 'c4'\n",
    "for r in rounds:\n",
    "    f_ref = os.path.join(spot_dir, f'spots_{r}_{c_ref}.txt')\n",
    "    f_qry = os.path.join(spot_dir, f'spots_{r}_{c_qry}.txt')\n",
    "    f_qry_removed = os.path.join(spot_dir, f'removed_spots_{r}_{c_qry}.txt')\n",
    "    \n",
    "    ref_dots = np.loadtxt(f_ref, delimiter=',')\n",
    "    qry_dots = np.loadtxt(f_qry, delimiter=',')\n",
    "    qry_kept, qry_removed = spot.remove_bleed_thru_spots(ref_dots, qry_dots, epsilon=bleed_thru_epsilon)\n",
    "    \n",
    "    # keep kept \n",
    "    spots_bld_thru_removed[f\"{r}_{c_qry}\"] = qry_kept\n",
    "    # save removed\n",
    "    np.savetxt(f_qry_removed, qry_removed, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd767d92-47eb-449b-9455-fc9522d2fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# count spots\n",
    "lb_id = np.unique(lb[lb!=0]) # exclude 0\n",
    "lb_id = np.hstack([[0], lb_id]) # include 0\n",
    "spotcount = pd.DataFrame(index=lb_id)\n",
    "for i, (r, c) in enumerate(itertools.product(rounds, channels)):\n",
    "    if f\"{r}_{c}\" in spots_bld_thru_removed.keys():\n",
    "        print(f\"{r}_{c}: load from bleed_thru_corrected spots\")\n",
    "        spots_rc = spots_bld_thru_removed[f\"{r}_{c}\"]\n",
    "    else:\n",
    "        f_spots = fx_spots[i]\n",
    "        print(f\"{r}_{c}: load from {f_spots}\")\n",
    "        spots_rc = np.loadtxt(f_spots, delimiter=',')\n",
    "        \n",
    "    res = spot.spot_counts_worker(lb, spots_rc, lb_id=lb_id, \n",
    "                             remove_emptymask=True, \n",
    "                             verbose=True,\n",
    "                             )\n",
    "    spotcount[f\"{r}_{c}\"] = res \n",
    "spotcount = spotcount.iloc[1:] # remove 0\n",
    "spotcount.to_csv(out_spots)\n",
    "spotcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd090cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot count calculated from total fluorescence intensity\n",
    "spotcount_intn = pd.DataFrame(index=roi_meta.index, dtype=float)\n",
    "for i, (r, c) in enumerate(itertools.product(rounds, channels)):\n",
    "    f_spots = fx_spots[i]\n",
    "    f_intns = fx_intns[i]\n",
    "    print(r, c, f_spots, f_intns)\n",
    "    \n",
    "    vec_count = get_spot_counts_from_intn(f_intns, f_spots, roi_meta)\n",
    "    spotcount_intn[f'{r}_{c}'] = vec_count\n",
    "spotcount_intn.to_csv(out_spots_intn)\n",
    "spotcount_intn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34116fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update spotcount using df_count\n",
    "spotcount_sub = spotcount.reindex(roi_meta.index)\n",
    "volumes = (roi_meta['area']*2*2*2/(0.92*0.92*0.84)) # convert um^3 to voxel values\n",
    "density = spotcount_sub.divide(volumes, axis=0)\n",
    "cond = density <= 0.01  ##this threshold corresponds to spot-spot distance ~1.3 um apart\n",
    "print((~cond).sum())\n",
    "spotcount_merged = spotcount_sub.where(cond, spotcount_intn)  \n",
    "spotcount_merged.to_csv(out_spots_merged)\n",
    "spotcount_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
