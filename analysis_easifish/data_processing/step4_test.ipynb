{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449cc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used to flag over-segmentation errors\n",
    "# A. maximize the number of identified errors\n",
    "# B. minimize false detection of well-segemented cells \n",
    "# \n",
    "# The over-segmentation pairs are identified with the following criteria: \n",
    "# 1) the two segments have a very high correlation (corr > 0.99) \n",
    "# \n",
    "# 2) the two segments have to be less than 55 pixels apart(centroid position distance)\n",
    "# \n",
    "# 3) at least one of the segments have to be bigger than 7000 pixels in size\n",
    "# \n",
    "# 4) The two segments have to be touching each other\n",
    "# \n",
    "# 5) if both segments are bigger than 20000 in size, it will be flagged and manually inspected\n",
    "# \n",
    "# 6) for ROIs that have more than two corresponding pairs, the corresponding segments will be ranked by correlation coefficient, and they will be flagged for manual inspection\n",
    "# \n",
    "# #1 and #2 are for initial identification of oversegmentation errors \n",
    "# \n",
    "# #3, #4, #5 are for eliminating the false detections  \n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "from skimage.io import imread, imsave\n",
    "from os.path import abspath, dirname\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance,cKDTree\n",
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "r1_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\\\\r1\\\\\"\n",
    "r2_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\\\\r2\\\\\"\n",
    "\n",
    "# lb_dir = \"/LHA3_R3_medium/segmentation/LHA3_R3_medium-c2.tif\"\n",
    "# bad_roi='/test/bad_roi_list.npy'\n",
    "# spot_dir = '/test/LHA3_R3_medium/spots/'\n",
    "# out_dir = '/test/LHA3_R3_medium/spots/'\n",
    "# img_dir='/test/LHA3_R3_medium/stitching/export.n5'\n",
    "\n",
    "\n",
    "fix_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\\\\r2\\\\export_sigma3.n5\"\n",
    "reg_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\\\\r1\\\\registration\\\\lt171_gene_4tile_r1-to-lt171_gene_4tile_r2\\\\warped\"  # directory to the registered image\n",
    "out_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\\\\r1\\\\registration\\\\lt171_gene_4tile_r1-to-lt171_gene_4tile_r2\\\\warped\\\\testout-july29\"  # where the output files should be saved \n",
    "lb_dir  = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\\\\r2\\\\segmentation\\\\lt171_gene_4tile_r2-c3.tif\"  # directory to the segmentation mask (tif format accepted here)\n",
    "\n",
    "bad_roi = os.path.join(out_dir, \"bad_roi_list.npy\")\n",
    "spot_dir = os.path.join(r2_dir, \"spots\")\n",
    "out_dir = spot_dir\n",
    "img_dir = fix_dir\n",
    "\n",
    "print(bad_roi)\n",
    "print(spot_dir)\n",
    "\n",
    "\n",
    "# ----\n",
    "\n",
    "# input\n",
    "# spotcount_dir      = sys.argv[1]  # directory to assigned spots per neuron based on airlocalize (csv format)\n",
    "# roi_dir            = sys.argv[2]  # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "# GeneName_dir       = sys.argv[3]  # directory to file containing marker gene metadata (gene name, corresponding imaging round and image channel)\n",
    "# spot_dir           = sys.argv[4]  # directory to folder of airlocalize output (1 file/gene, txt format)\n",
    "# intensity_dir      = sys.argv[5]  # directory to folder of intensity measurement output (1 file/gene, csv format)\n",
    "# output_dir         = sys.argv[6]  # directory where output should be stored\n",
    "output_dir = \"D:\\\\SWAP\\\\Vincent\\\\lt171_FlpO\\\\gene_new_4tile\\\\outputs\\\\\"\n",
    "\n",
    "spotcount_dir = os.path.join(spot_dir, 'spots.csv')\n",
    "roi_dir = os.path.join(spot_dir, 'roi.csv')\n",
    "GeneName_dir = os.path.join(output_dir, 'GeneName.csv')\n",
    "# spot_dir = \"\"\n",
    "intensity_dir = os.path.join(r2_dir, 'intensities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ba783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_dir      = sys.argv[1]  # directory to spot count/neuron (csv format)\n",
    "# roi_dir        = sys.argv[2]  # directory to neuron metadata (csv format)\n",
    "# lb_dir         = sys.argv[3]  # directory to segmentation mask (tif format)\n",
    "# out_dir        = sys.argv[4]  # directory to save output\n",
    "\n",
    "\n",
    "count_dir = os.path.join(output_dir, \"spotcount_dense_spot_corrected.csv\")  # directory to spot count/neuron (csv format)\n",
    "roi_dir = roi_dir\n",
    "lb_dir = lb_dir\n",
    "out_dir = output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51712290",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df=pd.read_csv(count_dir,sep=',', index_col=0)\n",
    "roi=pd.read_csv(roi_dir,sep=',',index_col=0).set_index('roi')\n",
    "df = df.reindex(roi.index)\n",
    "\n",
    "###Get correlation matrix\n",
    "corr_raw =df.T.corr()\n",
    "s_raw = corr_raw.stack()\n",
    "ii_raw = s_raw[np.logical_and(s_raw > 0.998, s_raw<1.0)].index.tolist()\n",
    "test=np.asarray(ii_raw)\n",
    "test.sort(axis=1)\n",
    "test=np.unique(test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db3c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7028af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45945fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(roi['area'] > 7000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e866353",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.loc[11724]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand={}\n",
    "for i in range(0,len(test)):\n",
    "#     a=roi.loc[float(test[i,0])].to_numpy()[:3]\n",
    "#     b=roi.loc[float(test[i,1])].to_numpy()[:3]\n",
    "    \n",
    "    a=roi.loc[test[i,0]].to_numpy()[:3]\n",
    "    b=roi.loc[test[i,1]].to_numpy()[:3]\n",
    "    \n",
    "    \n",
    "    dist=distance.euclidean(a,b)\n",
    "    if dist<55 and dist>0:\n",
    "#         a_area=roi.loc[float(test[i,0])]['area']\n",
    "#         b_area=roi.loc[float(test[i,1])]['area']\n",
    "        \n",
    "        \n",
    "        a_area=roi.loc[test[i,0]]['area']\n",
    "        b_area=roi.loc[test[i,1]]['area']\n",
    "        \n",
    "        if np.maximum(a_area,b_area) >7000:\n",
    "            c=corr_raw.loc[test[i,0],test[i,1]]\n",
    "            cand[i] = np.append(test[i,:],c)\n",
    "            cand[i] = np.append(cand[i],dist)\n",
    "            if np.minimum(a_area,b_area) >20000:\n",
    "                cand[i]=np.append(cand[i], str('atten'))\n",
    "            else:\n",
    "                cand[i]=np.append(cand[i], str('--'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=pd.DataFrame.from_dict(data=cand, orient='index')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf41f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = m.rename(columns={1:'cell_A', 2:'cell_B', 3: 'corr', 4:'dist',5: 'min_size_20000'})\n",
    "m['cell_A'], m['cell_B'] = np.where(m['cell_A'] > m['cell_B'], [m['cell_B'],m['cell_A'] ], [m['cell_A'] , m['cell_B']])\n",
    "\n",
    "lb=imread(lb_dir)\n",
    "lb_stat=regionprops(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "select={}\n",
    "for k in range(0,len(m)):\n",
    "    #a=np.argwhere(lb_4==n.iloc[k]['cell_A'])\n",
    "    #b=np.argwhere(lb_4==n.iloc[k]['cell_B'])\n",
    "    id1=m.iloc[k]['cell_A'].copy()\n",
    "    id2=m.iloc[k]['cell_B'].copy()\n",
    "    a=lb_stat[int(id1-1)].coords\n",
    "    b=lb_stat[int(id2-1)].coords\n",
    "    kdtree_a = cKDTree(a)\n",
    "    kdtree_b = cKDTree(b)\n",
    "    #neighbors = kdtree_a.query_ball_tree(kdtree_b, 1)\n",
    "    nnn=kdtree_a.count_neighbors(kdtree_b,1)\n",
    "    if nnn>0:\n",
    "        select[k]=m.iloc[k]\n",
    "        if nnn<50:\n",
    "            select[k]=np.append(select[k], str('less_50'))\n",
    "        else:\n",
    "            select[k]=np.append(select[k], str('--'))\n",
    "select=pd.DataFrame.from_dict(data=select, orient='index')\n",
    "select = select.rename(columns={0:'cell_A', 1:'cell_B', 2: 'corr', 3:'dist',4: 'min_size_20000',5:'touch'})\n",
    "\n",
    "select.to_csv(os.path.join(out_dir, 'flag_oversegmentation.csv'))\n",
    "## This output a list of oversegmented ROI pairs, with some flagged for manual inspection. After manual inspection, the list can be used to merge the oversegmented ROI pairs.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04558f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801347c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1809d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
